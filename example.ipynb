{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "106ded66-d202-46ac-82b0-2755ca309bdd",
   "metadata": {},
   "source": [
    "https://github.com/BAMresearch/NFDI4IngScientificWorkflowRequirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c7f6bb0-6227-48fa-84cb-56ba3af37897",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from pyiron_base import Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a016b3ce-13a8-4efc-9e69-6ab530d32cb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env_dict = {\n",
    "    \"preprocessing\": \"source/envs/preprocessing.yaml\",\n",
    "    \"processing\": \"source/envs/processing.yaml\",\n",
    "    \"postprocessing\": \"source/envs/postprocessing.yaml\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d416b603-92ee-4419-8f3a-e9179854f56e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_env(env_key, env_dict=env_dict):\n",
    "    subprocess.check_output(\n",
    "        [\"mamba\", \"env\", \"create\", \"-n\", env_key, \"-f\", env_dict[env_key], \"-y\"],\n",
    "        universal_newlines=True,\n",
    "    ).split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16ebffea-76b1-465e-aacb-ec68e1f895c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "paper_source = \"source/paper.tex\"\n",
    "macros_source = \"source/macros.tex.template\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e09b78-cb72-465f-9c8b-5b77f0aa729c",
   "metadata": {},
   "source": [
    "# Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a64ea6ec-1b30-4ef3-ae42-06aa95a35174",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env_key = \"preprocessing\"\n",
    "create_env(env_key=env_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed3af818-4355-482a-9c7b-107b9665ea59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pr_pre = Project(env_key)\n",
    "pr_pre.remove_jobs(recursive=True, silently=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1e22d2-9ce5-488f-8048-308d7d5d4966",
   "metadata": {},
   "source": [
    "## generate mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71d411b6-cbec-489e-99e3-ba71680bcb5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_input(input_dict, working_directory):\n",
    "    script_name = os.path.join(working_directory, \"gmsh.sh\")\n",
    "    with open(script_name, \"w\") as f:\n",
    "        f.writelines(\"gmsh -2 -setnumber domain_size \" + str(input_dict[\"domain_size\"]) + \" unit_square.geo -o square.msh\")\n",
    "    os.chmod(script_name, 0o744)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0aae7342-2402-4f4e-8be0-a535aec764f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collect_output_empty(working_directory):\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a359db74-8427-4250-b2f8-340d28c3a1a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pr_pre.create_job_class(\n",
    "    class_name=\"GmshJob\",\n",
    "    write_input_funct=write_input,\n",
    "    collect_output_funct=collect_output_empty,\n",
    "    default_input_dict={\"domain_size\": 2.0},\n",
    "    executable_str=\"./gmsh.sh\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a0fba70-142b-4a2b-8a5f-c77dcc94c9c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The job gmsh was saved and received the ID: 1\n"
     ]
    }
   ],
   "source": [
    "job_gmsh = pr_pre.create.job.GmshJob(job_name=\"gmsh\")\n",
    "job_gmsh.server.conda_environment_path = os.path.join(\"/\", \"srv\", \"conda\", \"envs\", env_key)  # conda environment \n",
    "job_gmsh.restart_file_list.append(\"source/unit_square.geo\")  # copy input file from source directory \n",
    "job_gmsh.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019938e7-8b41-47a9-b226-00e05dabc193",
   "metadata": {},
   "source": [
    "## convert to xdmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1eff1a83-48de-43cb-98df-503f1e4d6535",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_input_empty(input_dict, working_directory):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9d68e68-b561-44fe-897c-1d8abd00f645",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pr_pre.create_job_class(\n",
    "    class_name=\"MeshioJob\",\n",
    "    write_input_funct=write_input_empty,\n",
    "    collect_output_funct=collect_output_empty,\n",
    "    default_input_dict={\"empty\": 0},\n",
    "    executable_str=\"meshio convert square.msh square.xdmf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d0d9804-f250-48b3-a5d0-a546d520f79b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The job meshio was saved and received the ID: 2\n"
     ]
    }
   ],
   "source": [
    "job_meshio = pr_pre.create.job.MeshioJob(job_name=\"meshio\")\n",
    "job_meshio.server.conda_environment_path = os.path.join(\"/\", \"srv\", \"conda\", \"envs\", env_key)  # conda environment \n",
    "job_meshio.restart_file_list.append(os.path.join(job_gmsh.working_directory, \"square.msh\"))  # copy file from previous job\n",
    "job_meshio.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb0b643-caaa-426c-9781-28703440e647",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33997e2f-1d67-4498-89c0-6dd81bb501dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env_key = \"processing\"\n",
    "create_env(env_key=env_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a7ac41d-c93c-4edd-995c-f2bef4596302",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pr_main = Project(env_key)\n",
    "pr_main.remove_jobs(recursive=True, silently=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11815a8b-319c-4ff3-8eae-330bf6e58eee",
   "metadata": {},
   "source": [
    "## poisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b69bcff-e2b1-4d4a-b62c-6a1c86eeb590",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collect_output(working_directory):\n",
    "    with open(os.path.join(working_directory, \"numdofs.txt\"), \"r\") as f:\n",
    "        return {\"numdofs\": int(f.read())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aad30df2-f2ac-4228-9e62-23ba42cc2348",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pr_main.create_job_class(\n",
    "    class_name=\"PoissonJob\",\n",
    "    write_input_funct=write_input_empty,\n",
    "    collect_output_funct=collect_output,\n",
    "    default_input_dict={\"empty\": 0},\n",
    "    executable_str=\"python poisson.py --mesh square.xdmf --degree 2 --outputfile poisson.pvd --num-dofs numdofs.txt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8fc48b9-7190-405c-8586-0c845b935608",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The job poisson was saved and received the ID: 3\n"
     ]
    }
   ],
   "source": [
    "job_poisson = pr_main.create.job.PoissonJob(job_name=\"poisson\")\n",
    "job_poisson.server.conda_environment_path = os.path.join(\"/\", \"srv\", \"conda\", \"envs\", env_key)  # conda environment \n",
    "job_poisson.restart_file_list.append(os.path.abspath(\"source/poisson.py\"))  # copy input file from source directory\n",
    "job_poisson.restart_file_list.append(os.path.join(job_meshio.working_directory, \"square.xdmf\"))  # copy file from previous job\n",
    "job_poisson.restart_file_list.append(os.path.join(job_meshio.working_directory, \"square.h5\"))  # copy file from previous job\n",
    "job_poisson.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0bdb50b-c710-413c-938f-4ed5e3c9982b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "357"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_poisson.output[\"numdofs\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8a8634-029e-4337-96a2-a1f284cb4c38",
   "metadata": {},
   "source": [
    "# Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19d53621-a9fb-44b4-94d8-e06ce48a3d25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env_key = \"postprocessing\"\n",
    "create_env(env_key=env_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a635847-9ee9-4c32-8535-3ee1e63018b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pr_post = Project(env_key)\n",
    "pr_post.remove_jobs(recursive=True, silently=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157c5386-91a3-4e21-ac65-8f947f2d62fa",
   "metadata": {},
   "source": [
    "## plot over line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e520fd6a-5e0c-4c57-a18b-f8ae8fb7c8a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pr_post.create_job_class(\n",
    "    class_name=\"PvbatchJob\",\n",
    "    write_input_funct=write_input_empty,\n",
    "    collect_output_funct=collect_output_empty,\n",
    "    default_input_dict={\"empty\": 0},\n",
    "    executable_str=\"pvbatch postprocessing.py poisson.pvd plotoverline.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c4a29b0-eb1e-490a-8be0-e03cfff15e0a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The job pvbatch was saved and received the ID: 4\n"
     ]
    }
   ],
   "source": [
    "job_pvbatch = pr_post.create.job.PvbatchJob(job_name=\"pvbatch\")\n",
    "job_pvbatch.server.conda_environment_path = os.path.join(\"/\", \"srv\", \"conda\", \"envs\", env_key)  # conda environment \n",
    "job_pvbatch.restart_file_list.append(os.path.abspath(\"source/postprocessing.py\"))  # copy input file from source directory\n",
    "job_pvbatch.restart_file_list.append(os.path.join(job_poisson.working_directory, \"poisson.pvd\"))  # copy file from previous job\n",
    "job_pvbatch.restart_file_list.append(os.path.join(job_poisson.working_directory, \"poisson000000.vtu\"))  # copy file from previous job\n",
    "job_pvbatch.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f1d4bd-b944-470f-9cf8-30e64a24eb6d",
   "metadata": {},
   "source": [
    "## substitute macros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0540eb59-b174-4af8-bb03-68c7671ade72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_input(input_dict, working_directory):\n",
    "    script_name = os.path.join(working_directory, \"macros.sh\")\n",
    "    with open(script_name, \"w\") as f:\n",
    "        f.writelines(\"python prepare_paper_macros.py --macro-template-file macros.tex.template --plot-data-path plotoverline.csv --domain-size \" + str(input_dict[\"domain_size\"]) + \" --num-dofs \" + str(input_dict[\"numdofs\"]) + \" --output-macro-file macros.tex\")\n",
    "    os.chmod(script_name, 0o744)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "287cfd22-ee3d-41fc-bb6b-6ace780331a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pr_post.create_job_class(\n",
    "    class_name=\"MacrosJob\",\n",
    "    write_input_funct=write_input,\n",
    "    collect_output_funct=collect_output_empty,\n",
    "    default_input_dict={\"domain_size\": 2.0, \"numdofs\": 100},\n",
    "    executable_str=\"./macros.sh\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a0a4c233-322d-4723-9627-62ca2487bfa9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The job macros was saved and received the ID: 5\n"
     ]
    }
   ],
   "source": [
    "job_macros = pr_post.create.job.MacrosJob(job_name=\"macros\")\n",
    "job_macros.input[\"numdofs\"] = job_poisson.output[\"numdofs\"]\n",
    "job_macros.server.conda_environment_path = os.path.join(\"/\", \"srv\", \"conda\", \"envs\", env_key)  # conda environment \n",
    "job_macros.restart_file_list.append(os.path.abspath(\"source/macros.tex.template\"))  # copy input file from source directory\n",
    "job_macros.restart_file_list.append(os.path.abspath(\"source/prepare_paper_macros.py\"))  # copy input file from source directory\n",
    "job_macros.restart_file_list.append(os.path.join(job_pvbatch.working_directory, \"plotoverline.csv\"))  # copy file from previous job\n",
    "job_macros.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2031b693-acf3-48bd-bb00-e33f669381e9",
   "metadata": {},
   "source": [
    "## compile paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fde9d0af-4dac-4c30-a061-d44cd8f812ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pr_post.create_job_class(\n",
    "    class_name=\"TectonicJob\",\n",
    "    write_input_funct=write_input_empty,\n",
    "    collect_output_funct=collect_output_empty,\n",
    "    default_input_dict={\"empty\": 0},\n",
    "    executable_str=\"tectonic paper.tex\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "43d1a93b-dade-40f8-bde4-caaafadc07f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The job tectonic was saved and received the ID: 6\n"
     ]
    }
   ],
   "source": [
    "job_tectonic = pr_post.create.job.TectonicJob(job_name=\"tectonic\")\n",
    "job_tectonic.server.conda_environment_path = os.path.join(\"/\", \"srv\", \"conda\", \"envs\", env_key)  # conda environment \n",
    "job_tectonic.restart_file_list.append(os.path.abspath(\"source/paper.tex\"))  # copy input file from source directory\n",
    "job_tectonic.restart_file_list.append(os.path.join(job_macros.working_directory, \"macros.tex\"))  # copy file from previous job\n",
    "job_tectonic.restart_file_list.append(os.path.join(job_pvbatch.working_directory, \"plotoverline.csv\"))  # copy file from previous job\n",
    "job_tectonic.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dceb6c8-c819-4367-b729-58a940aa2f87",
   "metadata": {},
   "source": [
    "# Overview\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a0f8c537-b4ad-4614-be15-f13f6335b979",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>status</th>\n",
       "      <th>chemicalformula</th>\n",
       "      <th>job</th>\n",
       "      <th>subjob</th>\n",
       "      <th>projectpath</th>\n",
       "      <th>project</th>\n",
       "      <th>timestart</th>\n",
       "      <th>timestop</th>\n",
       "      <th>totalcputime</th>\n",
       "      <th>computer</th>\n",
       "      <th>hamilton</th>\n",
       "      <th>hamversion</th>\n",
       "      <th>parentid</th>\n",
       "      <th>masterid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>finished</td>\n",
       "      <td>None</td>\n",
       "      <td>gmsh</td>\n",
       "      <td>/gmsh</td>\n",
       "      <td>None</td>\n",
       "      <td>/home/jovyan/preprocessing/</td>\n",
       "      <td>2024-01-31 08:10:34.431821</td>\n",
       "      <td>2024-01-31 08:10:36.629415</td>\n",
       "      <td>2.0</td>\n",
       "      <td>pyiron@jupyter-pyiron-2ddev-2dnfdi4ing-5fpyiron-5fbase-2d4iz5hsu6#1</td>\n",
       "      <td>ExecutableContainerJob</td>\n",
       "      <td>0.4</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>finished</td>\n",
       "      <td>None</td>\n",
       "      <td>meshio</td>\n",
       "      <td>/meshio</td>\n",
       "      <td>None</td>\n",
       "      <td>/home/jovyan/preprocessing/</td>\n",
       "      <td>2024-01-31 08:10:36.813045</td>\n",
       "      <td>2024-01-31 08:10:38.637439</td>\n",
       "      <td>1.0</td>\n",
       "      <td>pyiron@jupyter-pyiron-2ddev-2dnfdi4ing-5fpyiron-5fbase-2d4iz5hsu6#1</td>\n",
       "      <td>ExecutableContainerJob</td>\n",
       "      <td>0.4</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>finished</td>\n",
       "      <td>None</td>\n",
       "      <td>poisson</td>\n",
       "      <td>/poisson</td>\n",
       "      <td>None</td>\n",
       "      <td>/home/jovyan/processing/</td>\n",
       "      <td>2024-01-31 08:13:02.656179</td>\n",
       "      <td>2024-01-31 08:13:20.849038</td>\n",
       "      <td>18.0</td>\n",
       "      <td>pyiron@jupyter-pyiron-2ddev-2dnfdi4ing-5fpyiron-5fbase-2d4iz5hsu6#1</td>\n",
       "      <td>ExecutableContainerJob</td>\n",
       "      <td>0.4</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>finished</td>\n",
       "      <td>None</td>\n",
       "      <td>pvbatch</td>\n",
       "      <td>/pvbatch</td>\n",
       "      <td>None</td>\n",
       "      <td>/home/jovyan/postprocessing/</td>\n",
       "      <td>2024-01-31 08:14:50.814698</td>\n",
       "      <td>2024-01-31 08:14:53.917757</td>\n",
       "      <td>3.0</td>\n",
       "      <td>pyiron@jupyter-pyiron-2ddev-2dnfdi4ing-5fpyiron-5fbase-2d4iz5hsu6#1</td>\n",
       "      <td>ExecutableContainerJob</td>\n",
       "      <td>0.4</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>finished</td>\n",
       "      <td>None</td>\n",
       "      <td>macros</td>\n",
       "      <td>/macros</td>\n",
       "      <td>None</td>\n",
       "      <td>/home/jovyan/postprocessing/</td>\n",
       "      <td>2024-01-31 08:14:54.140261</td>\n",
       "      <td>2024-01-31 08:14:55.028075</td>\n",
       "      <td>0.0</td>\n",
       "      <td>pyiron@jupyter-pyiron-2ddev-2dnfdi4ing-5fpyiron-5fbase-2d4iz5hsu6#1</td>\n",
       "      <td>ExecutableContainerJob</td>\n",
       "      <td>0.4</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>finished</td>\n",
       "      <td>None</td>\n",
       "      <td>tectonic</td>\n",
       "      <td>/tectonic</td>\n",
       "      <td>None</td>\n",
       "      <td>/home/jovyan/postprocessing/</td>\n",
       "      <td>2024-01-31 08:14:55.237259</td>\n",
       "      <td>2024-01-31 08:15:53.173338</td>\n",
       "      <td>57.0</td>\n",
       "      <td>pyiron@jupyter-pyiron-2ddev-2dnfdi4ing-5fpyiron-5fbase-2d4iz5hsu6#1</td>\n",
       "      <td>ExecutableContainerJob</td>\n",
       "      <td>0.4</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    status chemicalformula       job     subjob projectpath  \\\n",
       "0   1  finished            None      gmsh      /gmsh        None   \n",
       "1   2  finished            None    meshio    /meshio        None   \n",
       "2   3  finished            None   poisson   /poisson        None   \n",
       "3   4  finished            None   pvbatch   /pvbatch        None   \n",
       "4   5  finished            None    macros    /macros        None   \n",
       "5   6  finished            None  tectonic  /tectonic        None   \n",
       "\n",
       "                        project                  timestart  \\\n",
       "0   /home/jovyan/preprocessing/ 2024-01-31 08:10:34.431821   \n",
       "1   /home/jovyan/preprocessing/ 2024-01-31 08:10:36.813045   \n",
       "2      /home/jovyan/processing/ 2024-01-31 08:13:02.656179   \n",
       "3  /home/jovyan/postprocessing/ 2024-01-31 08:14:50.814698   \n",
       "4  /home/jovyan/postprocessing/ 2024-01-31 08:14:54.140261   \n",
       "5  /home/jovyan/postprocessing/ 2024-01-31 08:14:55.237259   \n",
       "\n",
       "                    timestop  totalcputime  \\\n",
       "0 2024-01-31 08:10:36.629415           2.0   \n",
       "1 2024-01-31 08:10:38.637439           1.0   \n",
       "2 2024-01-31 08:13:20.849038          18.0   \n",
       "3 2024-01-31 08:14:53.917757           3.0   \n",
       "4 2024-01-31 08:14:55.028075           0.0   \n",
       "5 2024-01-31 08:15:53.173338          57.0   \n",
       "\n",
       "                                                              computer  \\\n",
       "0  pyiron@jupyter-pyiron-2ddev-2dnfdi4ing-5fpyiron-5fbase-2d4iz5hsu6#1   \n",
       "1  pyiron@jupyter-pyiron-2ddev-2dnfdi4ing-5fpyiron-5fbase-2d4iz5hsu6#1   \n",
       "2  pyiron@jupyter-pyiron-2ddev-2dnfdi4ing-5fpyiron-5fbase-2d4iz5hsu6#1   \n",
       "3  pyiron@jupyter-pyiron-2ddev-2dnfdi4ing-5fpyiron-5fbase-2d4iz5hsu6#1   \n",
       "4  pyiron@jupyter-pyiron-2ddev-2dnfdi4ing-5fpyiron-5fbase-2d4iz5hsu6#1   \n",
       "5  pyiron@jupyter-pyiron-2ddev-2dnfdi4ing-5fpyiron-5fbase-2d4iz5hsu6#1   \n",
       "\n",
       "                 hamilton hamversion parentid masterid  \n",
       "0  ExecutableContainerJob        0.4     None     None  \n",
       "1  ExecutableContainerJob        0.4     None     None  \n",
       "2  ExecutableContainerJob        0.4     None     None  \n",
       "3  ExecutableContainerJob        0.4     None     None  \n",
       "4  ExecutableContainerJob        0.4     None     None  \n",
       "5  ExecutableContainerJob        0.4     None     None  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Project(\".\").job_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c281408f-e63d-4380-a7e6-c595d49fbb8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
